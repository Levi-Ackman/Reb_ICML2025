1. The authors repeatedly assert that MedTS are “centralized” but provide no quantitative validation. / Is there a formal way to distinguish between centralized and non-centralized MedTS?

We apologize for the lack of clarity in presenting our quantitative validation within the main text. This validation, along with a formal distinction, is provided in Appendix A.8.

Formal Distinction: We formally distinguish centralized from non-centralized time series using two established metrics: the Spectral Centralization Index (SCI) and the Dynamic Influence Centralization (DIC). These metrics quantify the dominance of principal components and the normalized imbalance of influence, respectively, with higher values indicating stronger centralized behavior.

Quantitative Validation: As shown in Table 11 of the appendix, the EEG and ECG datasets (MedTS) we use exhibit significantly higher centralization values than general-purpose multivariate time series datasets (Energy, Climate). This quantitative evidence confirms our core hypothesis that MedTS possesses an inherently centralized structure, where a few dominant channels or physiological processes govern the global dynamics.

2. The paper omits direct comparisons with recent dual-dependency or TeCh-style models (e.g., GAFormer).We agree that a discussion and comparison with recent dual-dependency models is crucial. We have included a detailed discussion of GAFormer and Leddam in Appendix A.1.Comparison and Differentiation: We differentiate TeCh from these models based on two key axes: objective and mechanism55.Objective: GAFormer and Leddam primarily focus on time series forecasting, whereas our work, TeCh, focuses on MedTS classification6.Mechanism: GAFormer and Leddam are Transformer-based, relying on decentralized attention and incurring a quadratic complexity ($O(S^2)$) for inter-channel interactions7. In contrast, TeCh utilizes the centralized CoTAR module, which better aligns with MedTS' biological sources (brain/heart), operates with linear complexity ($O(S)$), and is more suitable for large-scale MedTS analysis8888.Experimental Results: A direct comparison in the classification task, as requested, is presented in Appendix Table 8. The results demonstrate the superior performance of TeCh in MedTS classification.

3. The proposed CoTAR conceptually resembles several prior Transformer modifications that employ global or auxiliary tokens to aggregate and redistribute information. The authors should discuss them. e,g,. CATS.We acknowledge the conceptual similarity to models that use auxiliary tokens for information aggregation. We will expand the related work section to explicitly discuss this category of models and delineate the novelty of CoTAR.Conceptual Similarity: CoTAR is a centralized, MLP-based module that uses a global core token as a proxy to aggregate information from all tokens and then redistribute it back to each token9999. This is conceptually similar to auxiliary/global token designs like CATS and others.Novelty and Differentiation:Centralized Inductive Bias: CoTAR’s design is explicitly motivated by the centralized nature of biological signals (EEG/ECG)10101010, which is a domain-specific inductive bias absent in general-purpose auxiliary token models. Our analogy to a "star-shaped centralized system" where a central server mediates communication further highlights this distinction11111111.Mechanism and Complexity: CoTAR is an entirely MLP-based mechanism that completely replaces the attention module12121212. This design choice is engineered to achieve linear complexity ($O(S)$) and computational efficiency, which is essential for the long and high-dimensional sequences common in MedTS13


4. Different datasets use different hyperparameters.The use of dataset-specific hyperparameters, particularly in the number of encoder layers for the temporal ($M$) and channel ($N$) branches, is a deliberate design choice that reflects the Adaptive Dual Tokenization strategy in the TeCh framework1414.Justification: MedTS datasets are highly heterogeneous. Some datasets exhibit stronger temporal dependencies (favoring a larger $M$) while others are governed by stronger channel dependencies (favoring a larger $N$)151515.Adaptability: The TeCh framework is designed to adaptively capture Temporal dependencies, Channel dependencies, or both, by tuning the tokenization strategy and the number of layers in each branch16161616. This flexibility allows our model to achieve superior performance across diverse biological signals17. For example, Ablation Studies (Table 4 in the appendix) show that Temporal tokenization excels on TDBrain, while Channel tokenization excels on PTB18. The optimal hyperparameter setting is thus a direct result of this necessary adaptation to the intrinsic patterns of each dataset.

5. Can the core token be interpreted or visualized to correspond to physiological latent processes?
Yes, the core token can be both interpreted and visualized to correspond to physiological latent processes. This analysis is presented in Appendix C.7.


Visualization: Our T-SNE visualization of the core token demonstrates that it consistently occupies a central position in both the temporal and channel embedding spaces. This suggests it successfully captures a latent global physiological state.



Physiological Interpretation:

Temporal Space: The core token's temporal aggregation mirrors cross-temporal integration. For EEG, this aligns with slow cortical dynamics and low-frequency coherence (e.g., alpha/beta bands). For ECG, it parallels the beat-to-beat coordination and rhythmic discharge of the sinus node.


Channel Space: Its centralization in the channel space mirrors spatial integration across sensors. For EEG, this reflects the global workspace and hub-based integration unifying distributed cortical regions. For ECG, it reflects pacemaker synchronization across myocardial conduction pathways.
